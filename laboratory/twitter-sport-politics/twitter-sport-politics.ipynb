{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc36f26f-024e-433b-9987-577ff657b8b8",
   "metadata": {},
   "source": [
    "# Lab 2: sport vs politics\n",
    "\n",
    "**Requirement:**\n",
    "\n",
    "Build a system that:\n",
    "\n",
    "1. Everyday collects a large set of random tweets and groups them in tweets about politics and about sport\n",
    "2. For each of the two groups, shows the main topics of discussion\n",
    "\n",
    "## Data Collection\n",
    "\n",
    "Tweepy is a Python library for accessing the Twitter API. Here is used to extract text from the tweets to build our dataset.\n",
    "\n",
    "First we authenticate in order to use the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dfae6a6-b19d-46a5-9be3-18498b16f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "bearer_token = \"your bearer token\" # Twitter API\n",
    "client = tweepy.Client(bearer_token=bearer_token) # OAuth2.0 Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51cd4e5-b59f-4a3d-91fe-7ce4c6b66415",
   "metadata": {},
   "source": [
    "Three request are made to get the tweets from the topics:\n",
    "- sport\n",
    "- politics\n",
    "- random topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53824b3-4a81-42cc-837d-c74e293c4c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agustin/opt/anaconda3/envs/ml_lab/lib/python3.9/site-packages/tweepy/client.py:157: RuntimeWarning: Tweet data missing default edit_history_tweet_ids field\n",
      "  data = [data_type(result) for result in data]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "limit = 1000 # nr. tweets\n",
    "\n",
    "# request sports tweets\n",
    "query_sports = 'context:47.10050757844 -is:retweet lang:en'\n",
    "tweets_sports = tweepy.Paginator(client.search_recent_tweets, query=query_sports,\n",
    "                              tweet_fields=['text'], max_results=100).flatten(limit=limit)\n",
    "\n",
    "df_tweets_sports = pd.DataFrame([tweet.text for tweet in tweets_sports]) # convert to pandas df\n",
    "\n",
    "# request politics tweets\n",
    "query_politics = 'context:131.1291447199595782144 -is:retweet lang:en'\n",
    "tweets_politics = tweepy.Paginator(client.search_recent_tweets, query=query_politics,\n",
    "                              tweet_fields=['text'], max_results=100).flatten(limit=limit)\n",
    "\n",
    "df_tweets_politics = pd.DataFrame([tweet.text for tweet in tweets_politics]) # convert to pandas df\n",
    "\n",
    "# request random tweets\n",
    "query_random = 'a lang:en' # fix this\n",
    "tweets_random = tweepy.Paginator(client.search_recent_tweets, query=query_random,\n",
    "                              tweet_fields=['text'], max_results=100).flatten(limit=limit)\n",
    "\n",
    "df_tweets_random = pd.DataFrame([tweet.text for tweet in tweets_random]) # convert to pandas df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89231a60-8c82-4eba-bea4-270099840863",
   "metadata": {},
   "source": [
    "The three groups will be the labels for each class, so in future they can be used with supervised learning.\n",
    "\n",
    "Then all the collected data is concatenated in an unique dataset and saved to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b65188-7f45-4f55-94bb-b0cc7e3faaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@NGB2020 @LivingWillie @KariLake @katiehobbs E...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What‚Äôs going on in the #arizonaelections is di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Have been spoon-fed some delightful bits of th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@RepJayapal That still wouldn't stop the crime...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@HawleyMO Thank you for supporting the Branson...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>RT @dirmaxdeyforU: A Thread of Hilarious Photo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>RT @labtech666: First test run of a salad bowl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>RT @AdoptionsUk: Please retweet to help Indy f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>RT @dollkura: ‚òÜ gcash giveaway ! because it‚Äôs ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>RT @RCD_Mallorca: üë∫ Fet a ùêíùê®ùêß ùêÅùê¢ùêõùê¢ùê•ùê®ùêßùê¢. A casa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     X  y\n",
       "0    @NGB2020 @LivingWillie @KariLake @katiehobbs E...  1\n",
       "1    What‚Äôs going on in the #arizonaelections is di...  1\n",
       "2    Have been spoon-fed some delightful bits of th...  1\n",
       "3    @RepJayapal That still wouldn't stop the crime...  1\n",
       "4    @HawleyMO Thank you for supporting the Branson...  1\n",
       "..                                                 ... ..\n",
       "995  RT @dirmaxdeyforU: A Thread of Hilarious Photo...  2\n",
       "996  RT @labtech666: First test run of a salad bowl...  2\n",
       "997  RT @AdoptionsUk: Please retweet to help Indy f...  2\n",
       "998  RT @dollkura: ‚òÜ gcash giveaway ! because it‚Äôs ...  2\n",
       "999  RT @RCD_Mallorca: üë∫ Fet a ùêíùê®ùêß ùêÅùê¢ùêõùê¢ùê•ùê®ùêßùê¢. A casa...  2\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add label column\n",
    "df_tweets_sports['y'] = 0\n",
    "df_tweets_politics['y'] = 1\n",
    "df_tweets_random['y'] = 2\n",
    "\n",
    "\n",
    "# concatenate data by rows\n",
    "df_D = pd.concat([df_tweets_politics, df_tweets_sports, df_tweets_random], axis = 0)\n",
    "df_D = df_D.rename({0: 'X',}, axis=1) # rename features data to X\n",
    "display(df_D)\n",
    "\n",
    "# export to csv\n",
    "df_D.to_csv(\"data/dataset.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1739c986-9a6e-463f-8682-f968cc39c296",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-processing\n",
    "\n",
    "Collected data is loaded from the .csv file.\n",
    "\n",
    "The dataset is composed by tweets labeled by politics and sport topics.\n",
    "- y=0 are sport tweets\n",
    "- y=1 are politics tweets\n",
    "- y=2 are random tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03604aea-68fe-432a-ab08-b5066ea1c641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@NGB2020 @LivingWillie @KariLake @katiehobbs E...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What‚Äôs going on in the #arizonaelections is di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Have been spoon-fed some delightful bits of th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@RepJayapal That still wouldn't stop the crime...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@HawleyMO Thank you for supporting the Branson...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>995</td>\n",
       "      <td>RT @dirmaxdeyforU: A Thread of Hilarious Photo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>996</td>\n",
       "      <td>RT @labtech666: First test run of a salad bowl...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>997</td>\n",
       "      <td>RT @AdoptionsUk: Please retweet to help Indy f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>998</td>\n",
       "      <td>RT @dollkura: ‚òÜ gcash giveaway ! because it‚Äôs ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>999</td>\n",
       "      <td>RT @RCD_Mallorca: üë∫ Fet a ùêíùê®ùêß ùêÅùê¢ùêõùê¢ùê•ùê®ùêßùê¢. A casa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                                  X  y\n",
       "0              0  @NGB2020 @LivingWillie @KariLake @katiehobbs E...  1\n",
       "1              1  What‚Äôs going on in the #arizonaelections is di...  1\n",
       "2              2  Have been spoon-fed some delightful bits of th...  1\n",
       "3              3  @RepJayapal That still wouldn't stop the crime...  1\n",
       "4              4  @HawleyMO Thank you for supporting the Branson...  1\n",
       "...          ...                                                ... ..\n",
       "2995         995  RT @dirmaxdeyforU: A Thread of Hilarious Photo...  2\n",
       "2996         996  RT @labtech666: First test run of a salad bowl...  2\n",
       "2997         997  RT @AdoptionsUk: Please retweet to help Indy f...  2\n",
       "2998         998  RT @dollkura: ‚òÜ gcash giveaway ! because it‚Äôs ...  2\n",
       "2999         999  RT @RCD_Mallorca: üë∫ Fet a ùêíùê®ùêß ùêÅùê¢ùêõùê¢ùê•ùê®ùêßùê¢. A casa...  2\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset\n",
    "df_D = pd.read_csv(\"data/dataset.csv\")\n",
    "display(df_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff014d-9510-4c6b-82a5-aa0bd3a8e2b9",
   "metadata": {},
   "source": [
    "### Bag-of-Words\n",
    "\n",
    "Is used the scikit-learn implementation of bag of word using the CountVectorizer class.\n",
    "It take an array of text as input and return a bag-of-words model.\n",
    "\n",
    "#### Less frequently words\n",
    "To lower the dimension we can clean the words that appears less frequently, is used the \"min_df\" to set the minimum number of documents that the word needs to appear in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37911be1-704e-4174-8582-fb187eea198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 1646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(min_df=5)\n",
    "count.fit(df_D.loc[:,'X']) # generate Bag-of-words model\n",
    "\n",
    "print(\"Vocabulary size: {}\". format(len(count.vocabulary_)))\n",
    "#print(\"Vocabulary content:\\n {}\".format(count.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e935a76-7a40-4a44-8462-6da8754c3d78",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "We can further improve our bag-of-words pre-processing using a normalization technique called stemming.\n",
    "The idea is to reduce each word to its stem, using the stemming algorithm (rule-based heuristic).\n",
    "For example a stemmer reduce words like \"climber\", \"climbed\" and \"climbing\" to \"climb\".\n",
    "\n",
    "The Natural Language Toolkit for Python (NLTK, http://www.nltk.org) implements the Snowball stemming algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99841a60-b3b9-4f98-b527-d9e59584f4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agustin/opt/anaconda3/envs/ml_lab/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size using stemming: 1610\n"
     ]
    }
   ],
   "source": [
    "# Apply advance tokenization\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# create a function to \n",
    "def tokenizer_snowballStemmer(text):\n",
    "    return [stemmer.stem(word) for word in text.split()]\n",
    "\n",
    "tokenizer_snowballStemmer(\"The pink sweater fit her perfectly\") # test\n",
    "\n",
    "count = CountVectorizer(tokenizer = tokenizer_snowballStemmer, min_df=5) # use tokenizer function\n",
    "count.fit(df_D.loc[:,'X']) # generate Bag-of-words\n",
    "\n",
    "print(\"Vocabulary size using stemming: {}\". format(len(count.vocabulary_)))\n",
    "#print(\"Vocabulary content:\\n {}\".format(count.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3c160-e660-4788-8320-7da6b324cda5",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Shuffle and divide the data in Training and Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfc818d-84b7-4a5a-be02-e9af8137dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_D.loc[:,'X'], df_D.loc[:,'y'], test_size=0.3, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999f5ef-af11-4d06-a7f0-835ec5970151",
   "metadata": {},
   "source": [
    "Then apply the previous pre-processing methods for text. The transformation is applied to the Training set and then the Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0881e328-bd9d-4030-adc6-a2a2dbc6676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2100, 1162)\n",
      "X_test: (900, 1162)\n"
     ]
    }
   ],
   "source": [
    "# generate bag of word model\n",
    "count = CountVectorizer(tokenizer=tokenizer_snowballStemmer, min_df=5).fit(X_train)\n",
    "\n",
    "# apply transformation to the data\n",
    "X_train_bow = count.transform(X_train)\n",
    "print(\"X_train: {}\".format(X_train_bow.shape))\n",
    "\n",
    "X_test_bow = count.transform(X_test)\n",
    "print(\"X_test: {}\".format(X_test_bow.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e28ad-31df-4783-b872-7c2a72c6c13e",
   "metadata": {},
   "source": [
    "Fit a Random Forest model on the Training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7fc189a-5c25-4787-a71e-8aee996c5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# fit a Random Forest model\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e490dbe4-f8b6-4c4d-9bc0-78c298daff0b",
   "metadata": {},
   "source": [
    "Check the model performance using cross validation (on the training set) and show the accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "730735f3-b088-417a-a5ba-80bbb9035c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cross Validation scores'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy cv=1: 92.38'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy cv=2: 92.38'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy cv=3: 90.48'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy cv=4: 93.1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy cv=5: 90.95'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Accuracy MEAN: 92.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# plot CV results\n",
    "scores = cross_val_score(clf, X_train_bow, y_train, cv=5, scoring='accuracy')\n",
    "display(\"Cross Validation scores\")\n",
    "i=1\n",
    "for a in scores:\n",
    "    display(\"Accuracy cv=\" + str(i) + \": \" + str(round(a*100, 2)))\n",
    "    i = i+1\n",
    "\n",
    "display(\"Accuracy MEAN: \"+str(round(scores.mean(),2)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b113a3b-f2d6-49dc-bd8b-96c29fb04a4a",
   "metadata": {},
   "source": [
    "Now the model is tested on the Test set. Are then plotted the accuracy and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0655c89e-03f7-4e4f-8dc2-061117742e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test set accuracy: 92.78'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[284,  11,   5],\n",
       "       [  9, 287,   8],\n",
       "       [  5,  27, 264]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# results on test set\n",
    "predictions = clf.predict(X_test_bow)\n",
    "test_accuracy = accuracy_score(predictions, y_test)\n",
    "display(\"Test set accuracy: \" + str(round(test_accuracy*100, 2)))\n",
    "\n",
    "display(confusion_matrix(predictions, y_test)) # display confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef847f-4845-4a64-956d-99189b66679c",
   "metadata": {},
   "source": [
    "## Pre-processing (point 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac978e75-38c0-4a06-a3ec-360d405c8498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
